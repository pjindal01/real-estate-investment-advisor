{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f88205e",
   "metadata": {},
   "source": [
    "# Real Estate Investment Advisor\n",
    "\n",
    "## Problem Statement\n",
    "Estimate property profitability and future value using structured real estate data.\n",
    "\n",
    "## Approach\n",
    "Performed data cleaning, feature engineering, and trained a regression model to predict property value.\n",
    "\n",
    "## Evaluation\n",
    "Model performance evaluated using RMSE, MAE, and R².\n",
    "\n",
    "## Business Impact\n",
    "Supports data-driven real estate investment decisions by identifying high-return properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624487b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a42d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_read_csv helper (small)\n",
    "def safe_read_csv(path, nrows=None, dtype=None):\n",
    "        df = pd.read_csv(path, nrows=nrows, dtype=dtype)\n",
    "        df = pd.read_csv(path, nrows=nrows, dtype=dtype, low_memory=False)\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "df = pd.read_csv(DATA_P, low_memory=False)\n",
    "# safe_read_csv helper (small)\n",
    "def safe_read_csv(path, nrows=None, dtype=None):\n",
    "        df = pd.read_csv(path, nrows=nrows, dtype=dtype)\n",
    "        df = pd.read_csv(path, nrows=nrows, dtype=dtype, low_memory=False)\n",
    "    df = pd.read_csv(DATA_P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816d8b3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef348b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sample = \" \".join(df[col].dropna().astype(str).head(50).tolist())\n",
    "            df[col] = df[col].astype(float)\n",
    "        sample_vals = df[col].dropna().astype(str).head(50).tolist()\n",
    "        df.loc[:, c] = df[c].fillna(df[c].median())\n",
    "        df.loc[:, c] = df[c].fillna(\"Unknown\")\n",
    "df['growth_rate'] = df['roi_category'].map(growth_map).astype(float)   # <-- FIXED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87245412",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1539563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\"\"\"### **Correlations & Feature Relationships**\n",
    "# EDA Q11–Q15: Correlations & feature relationships\n",
    "print(\"Q11: Correlation matrix (numeric features):\")\n",
    "plt.title(\"Q11: Correlation Heatmap (Numeric Features)\")\n",
    "iso_features = df[['price_in_lakhs', 'price_per_sqft', 'size_in_sqft']]\n",
    "df['anomaly_flag'] = iso.fit_predict(iso_features)  # -1 = anomaly\n",
    "df['anomaly_score'] = iso.decision_function(iso_features)  # smaller = more anomalous\n",
    "\"\"\"## 07. Feature Engineering\n",
    "# === Feature Engineering – Targets for Regression & Classification ===\n",
    "\"\"\"### **EDA on Engineered Features & External Factors**\n",
    "# === Advanced Post-Feature-Engineering EDA ===\n",
    "\"\"\"### ➤ *Derived feature: Growth Ratio*\"\"\"\n",
    "# -------- 2. Derived feature: Growth Ratio --------\n",
    "\"\"\"### ➤ *Heatmap of Engineered Feature Correlations*\"\"\"\n",
    "# -------- 5. Heatmap of engineered feature correlations --------\n",
    "plt.title(\"Correlation of Engineered + Economic Features\")\n",
    "print(\"Professional Feature-Engineering EDA completed.\")\n",
    "print(\"✅ Post-feature-engineering EDA completed.\")\n",
    "### ➤ *Feature Preparation*\n",
    "# FEATURE PREPARATION\n",
    "# Core engineered features\n",
    "print(\"✅ Feature preparation completed. Created features:\")\n",
    "\"\"\"## **Advanced Feature Engineering**\n",
    "# ADVANCED FEATURE ENGINEERING: Age-based Bands\n",
    "print(\"✅ Age-based band feature 'property_age_band' added.\")\n",
    "# ADVANCED FEATURE ENGINEERING: Market Segmentation\n",
    "# Market Segmentation Feature: Divide properties into tiers based on price quantiles\n",
    "print(\"✅ Market segmentation feature 'market_tier' added.\")\n",
    "# Create 'market_tier' feature using pd.qcut\n",
    "print(\"✅ 'market_tier' feature has been added based on price quantiles.\")\n",
    "\"\"\"### ➤ *Locality Averaged Pricing Feature*\"\"\"\n",
    "print(\"✅ 'locality_avg_pps' feature has been added, representing the average price per square foot for each locality.\")\n",
    "\"\"\"### ➤ *City Premium Features*\"\"\"\n",
    "print(\"✅ 'city_pps_mean' and 'city_pps_deviation' features have been added.\")\n",
    "\"\"\"## **Feature Validation**\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "features_for_mi = df.select_dtypes(include=['int', 'float']).drop(columns=['future_price_5y', 'good_investment'])\n",
    "    features_for_mi,\n",
    "print(\"Top MI features for Classification (good_investment):\")\n",
    "mi_clf_features = sorted(zip(mi_clf, features_for_mi.columns), reverse=True)[:10]\n",
    "for score, feature in mi_clf_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "features_for_mi = df.select_dtypes(include=['int', 'float']).drop(columns=['future_price_5y', 'good_investment'])\n",
    "    features_for_mi,\n",
    "print(\"Top MI features for Classification (good_investment):\")\n",
    "mi_clf_features = sorted(zip(mi_clf, features_for_mi.columns), reverse=True)[:10]\n",
    "for score, feature in mi_clf_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "features_for_mi = df.select_dtypes(include=['int', 'float']).drop(columns=['future_price_5y', 'good_investment'])\n",
    "    features_for_mi,\n",
    "print(\"Top MI features for Regression (future_price_5y):\")\n",
    "mi_reg_features = sorted(zip(mi_reg, features_for_mi.columns), reverse=True)[:10]\n",
    "for score, feature in mi_reg_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "features_for_mi = df.select_dtypes(include=['int', 'float']).drop(columns=['future_price_5y', 'good_investment'])\n",
    "    features_for_mi,\n",
    "print(\"Top MI features for Regression (future_price_5y):\")\n",
    "mi_reg_features = sorted(zip(mi_reg, features_for_mi.columns), reverse=True)[:10]\n",
    "for score, feature in mi_reg_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "# DOMAIN FEATURE ENGINEERING\n",
    "print(\"✅ Domain-specific features added.\")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "        \"anomaly detection, and feature engineering (sections 02 through 07) \"\n",
    "\"\"\"### ➤ *Prepare Feature and Target DataFrames*\"\"\"\n",
    "# SECTION: Prepare Feature and Target DataFrames\n",
    "X = df[feature_cols].copy()\n",
    "print(\"✅ Feature (X) and Target (y_clf, y_reg) DataFrames prepared.\")\n",
    "\"\"\"### ➤ *Identify Numeric and Categorical Features*\"\"\"\n",
    "# SECTION: Identify Numeric and Categorical Features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "# Let's ensure they are in categorical features if they are object type and not already there\n",
    "    if col in X.columns and X[col].dtype == 'object' and col not in categorical_features:\n",
    "        categorical_features.append(col)\n",
    "    elif col in X.columns and X[col].dtype == 'bool' and col not in categorical_features:\n",
    "        categorical_features.append(col)\n",
    "# Filter out any features that might not exist after cleaning/engineering\n",
    "numeric_features = [f for f in numeric_features if f in X.columns]\n",
    "categorical_features = [f for f in categorical_features if f in X.columns]\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"✅ Feature types identified.\")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "print(\"✅ Preprocessing steps defined with StandardScaler and OneHotEncoder.\")\n",
    "X_current = df[feature_cols].copy()\n",
    "\"\"\"### ➤ *Feature Importance for Best Models*\"\"\"\n",
    "# === Feature Importance for Best Models (Random Forests) ===\n",
    "def get_feature_names_from_preprocessor(preprocessor, numeric_features, categorical_features):\n",
    "    num_features = numeric_features\n",
    "    cat_feature_names = list(cat_transformer.get_feature_names_out(categorical_features))\n",
    "    return num_features + cat_feature_names\n",
    "feature_names = get_feature_names_from_preprocessor(preprocessor, numeric_features, categorical_features)\n",
    "# Classification feature importance (if RF was used as best)\n",
    "    importances_clf = best_clf_model.named_steps['rf'].feature_importances_\n",
    "    feat_imp_clf = sorted(zip(feature_names, importances_clf), key=lambda x: x[1], reverse=True)[:20]\n",
    "    print(\"\\nTop 20 Important Features (Classification):\")\n",
    "    plt.title(\"Top 20 Feature Importances – Classification (RF)\")\n",
    "    print(\"Best classification model is not a Random Forest, so tree-based feature importance is not available.\")\n",
    "# Regression feature importance (if RF was used as best)\n",
    "    importances_reg = best_reg_model.named_steps['model'].feature_importances_\n",
    "    feat_imp_reg = sorted(zip(feature_names, importances_reg), key=lambda x: x[1], reverse=True)[:20]\n",
    "    print(\"\\nTop 20 Important Features (Regression):\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1076e",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636d817",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "clf_log.fit(X_train_clf, y_train_clf)\n",
    "clf_rf.fit(X_train_clf, y_train_clf)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "    ('model', LinearRegression())\n",
    "# Random Forest Regressor\n",
    "    ('model', RandomForestRegressor(\n",
    "reg_lin.fit(X_train_reg, y_train_reg)\n",
    "print(\"\\nTraining Random Forest Regressor...\")\n",
    "reg_rf.fit(X_train_reg, y_train_reg)\n",
    "    evaluate_regression_model(\"Random Forest Regressor\", reg_rf, X_test_reg, y_test_reg)\n",
    "    elif res['name'] == \"Random Forest Regressor\":\n",
    "        mlflow_log_model(\"reg_random_forest_regressor\", reg_rf, res)\n",
    "if isinstance(best_clf_model.named_steps['rf'], RandomForestClassifier):\n",
    "if isinstance(best_reg_model.named_steps['model'], RandomForestRegressor):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56622b71",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2  = r2_score(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
